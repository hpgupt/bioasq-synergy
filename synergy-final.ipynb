{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n",
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "EHlPinmMLJzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TzfErkVmw_lv"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import getpass\n",
        "import json\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = getpass.getpass(\"Enter your NCBI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrzhlJoRxLnc",
        "outputId": "98a7d29c-871d-4f96-bdeb-78a8db72a8e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your NCBI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mynK09v7TORj",
        "outputId": "56c1f460-2dc9-436e-91f6-0e069a4b78bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/BioASQ-taskSynergy_v2025-testset4.json', 'r') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "bmcwSdnN-xxl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[\"questions\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOKRe9FRO8qZ",
        "outputId": "b83a74ab-00ce-4eae-9256-d9589178f0fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Question keywords using LLM - don't run this again"
      ],
      "metadata": {
        "id": "CJ3FIeZFiDg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_list_prompt = PromptTemplate(\n",
        "    input_variables=[\"question_body\"],\n",
        "    template=\"\"\"\n",
        "You are an expert in formulating optimal PubMed search queries and biomedical information retrieval. Given the following question, generate 5 PubMed search queries that can be used to retrieve relevant articles from pubmed. Each query should:\n",
        "- Contain only single-word keywords separated by a space.\n",
        "- Replace any dash-connected words (e.g. \"early-onset\") with separate words (\"early onset\").\n",
        "- Be ordered from most specific (i.e. containing the most keywords) to least specific (with fewer keywords).\n",
        "- Remove less relevant or stop words first while keeping core biomedical or medical terms intact.\n",
        "- Queries should be ordered in decreasing order from most words to less words in them. Queries with more words will definetely be more useful to fetch\n",
        "more relevant articles but sometimes very specific search returns no articles, thus we gradually remove less relevant words usually not the biomedical terms\n",
        "from queries in hopes to retrieve some articles.\n",
        "- Do not explicitly insert logical operators like AND\n",
        "- Do not include stop words, punctuation , helper words (remove them outright), then gradually remove less relevant words over the 5 quesries generated.\n",
        "- The query you form will be used to get most relevant articles that can help answer the given question, thus the search query formed should be the most optimal.\n",
        "\n",
        "Question: {question_body}\n",
        "\n",
        "Return your answer in JSON format exactly matching the structure below:\n",
        "{{\n",
        "    \"queries\": [<string>, <string>, <string>, <string>, <string>]\n",
        "}}\n",
        "\"\"\"\n",
        ")\n",
        "class QueryList(BaseModel):\n",
        "    queries: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"A list of 5 PubMed queries ordered from most specific (with the most keywords) to least specific (with fewer keywords).\"\n",
        "    )\n",
        "\n",
        "llm_key = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
        "structured_key_llm = llm_key.with_structured_output(QueryList)"
      ],
      "metadata": {
        "id": "kWWkmKMaiLDj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_mapping = {}\n",
        "\n",
        "for question in data[\"questions\"]:\n",
        "    response = structured_key_llm.invoke(query_list_prompt.format(question_body=question[\"body\"]))\n",
        "    query_list = response.queries\n",
        "\n",
        "    selected_query = None\n",
        "    for q in query_list:\n",
        "        processed_query = q.replace(\"-\", \" \")\n",
        "        _, pmids, _ = generate_article_context(processed_query, api_key)\n",
        "        if pmids:\n",
        "            selected_query = processed_query\n",
        "            break\n",
        "\n",
        "    if not selected_query:\n",
        "        print(f\"No relevant articles found for question: '{question['body']}' using queries: {query_list}\")\n",
        "        selected_query = query_list[-1].replace(\"-\", \" \")\n",
        "\n",
        "    final_mapping[question[\"id\"]] = selected_query"
      ],
      "metadata": {
        "id": "k-uLw-9Ttf_E"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(final_mapping))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vs6VoULf2Su",
        "outputId": "94dfcbe4-2efd-4c00-d727-86bf337a5465"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"mapping2.json\", \"w\") as json_file:\n",
        "    json.dump(final_mapping, json_file, indent=4)"
      ],
      "metadata": {
        "id": "sdgraVgDt_LL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the mapping directly"
      ],
      "metadata": {
        "id": "Jybio43r63E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/mapping2.json\", \"r\") as json_file:\n",
        "    mapping = json.load(json_file)"
      ],
      "metadata": {
        "id": "4W8AI_9j62M7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djel8W3TQCgb",
        "outputId": "5520633e-0e0a-4829-8736-08e8bc7a8a64"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main task"
      ],
      "metadata": {
        "id": "c2BIC-1qiJS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_pubmed_documents(question_body, api_key):\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "    db = \"pubmed\"\n",
        "    retmax = 20  # Fetch atmax 20\n",
        "    esearch_url = f\"{base_url}esearch.fcgi?db={db}&term={question_body}&retmax={retmax}&retmode=xml&sort=relevance&api_key={api_key}\"\n",
        "\n",
        "    try:\n",
        "        # Fetch PMIDs\n",
        "        esearch_response = requests.get(esearch_url)\n",
        "        esearch_response.raise_for_status()\n",
        "        esearch_data_root = ET.fromstring(esearch_response.text)\n",
        "        pmids = [id_elem.text for id_elem in esearch_data_root.findall(\".//IdList/Id\")]\n",
        "\n",
        "        if not pmids:\n",
        "            # print(\"No PMIDs found for the query.\")\n",
        "            return {}, []\n",
        "\n",
        "        # Fetch article details\n",
        "        efetch_url = f\"{base_url}efetch.fcgi?db={db}&id={','.join(pmids)}&rettype=abstract&retmode=xml&api_key={api_key}\"\n",
        "        efetch_response = requests.get(efetch_url)\n",
        "        efetch_response.raise_for_status()\n",
        "        efetch_data_root = ET.fromstring(efetch_response.text)\n",
        "\n",
        "        documents = {}\n",
        "        pmid_ret = []\n",
        "\n",
        "        for article in efetch_data_root.findall(\".//PubmedArticle\"):\n",
        "            pmid = article.find(\".//PMID\").text\n",
        "\n",
        "            # Extract title\n",
        "            title_elem = article.find(\".//ArticleTitle\")\n",
        "            title = \" \".join(title_elem.itertext()).strip() if title_elem is not None else None\n",
        "\n",
        "            # Extract abstract\n",
        "            abstract_texts = []\n",
        "            for abstract in article.findall(\".//AbstractText\"):\n",
        "                abstract_texts.append(\" \".join(abstract.itertext()).strip())\n",
        "\n",
        "            abstract = \"\\n\".join(abstract_texts) if abstract_texts else None\n",
        "\n",
        "            # Skip if title or abstract is missing\n",
        "            if not title or not abstract:\n",
        "                continue\n",
        "\n",
        "            # Skip retracted articles\n",
        "            if any(\"Retracted Publication\" in pub_type.text for pub_type in article.findall(\".//PublicationTypeList/PublicationType\")):\n",
        "                continue\n",
        "\n",
        "            if len(abstract.split())>4000:\n",
        "              continue\n",
        "\n",
        "            documents[pmid] = {\"title\": title, \"abstract\": abstract}\n",
        "            pmid_ret.append(pmid)\n",
        "\n",
        "            if len(documents) >= 10:\n",
        "                break\n",
        "\n",
        "        return documents, pmid_ret\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "        return None\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"XML Parse error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "JKpf0oPAxRxZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YesNoAnswer(BaseModel):\n",
        "    ideal_answer: str = Field(\n",
        "        ...,\n",
        "        description=\"A paragraph-sized ideal answer summarizing the most relevant information (max 200 words).\"\n",
        "    )\n",
        "    exact_answer: str = Field(\n",
        "        ...,\n",
        "        description=\"Exact answer: must be either 'yes' or 'no'.\"\n",
        "    )\n",
        "\n",
        "class FactoidAnswer(BaseModel):\n",
        "    ideal_answer: str = Field(\n",
        "        ...,\n",
        "        description=\"A paragraph-sized ideal answer summarizing the most relevant information (max 200 words).\"\n",
        "    )\n",
        "    exact_answer: List[List[str]] = Field(\n",
        "        ...,\n",
        "        description=(\"A list of lists containing up to 5 entity names, ordered by decreasing confidence. \"\n",
        "                     \"Each inner list must contain only one element.\")\n",
        "    )\n",
        "\n",
        "class ListAnswer(BaseModel):\n",
        "    ideal_answer: str = Field(\n",
        "        ...,\n",
        "        description=\"A paragraph-sized ideal answer summarizing the most relevant information (max 200 words).\"\n",
        "    )\n",
        "    exact_answer: List[List[str]] = Field(\n",
        "        ...,\n",
        "        description=(\"A list of lists corresponding to the entities sought by the question. \"\n",
        "                     \"Each inner list must contain exactly one element (no synonyms allowed).\")\n",
        "    )\n",
        "\n",
        "class SummaryAnswer(BaseModel):\n",
        "    ideal_answer: str = Field(\n",
        "        ...,\n",
        "        description=\"A paragraph-sized ideal answer summarizing the most relevant information (max 200 words).\"\n",
        "    )"
      ],
      "metadata": {
        "id": "G_lT8C4LLU61"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yesno_prompt = PromptTemplate(\n",
        "    input_variables=[\"question_body\", \"articles_context\"],\n",
        "    template=\"\"\"\n",
        "You are a biomedical expert. Answer the following yes/no question based on the provided articles context. The articles are ordered by decreasing relevance.\n",
        "Don't mention about given articles in ideal answer, just use the knowledge given in articles and answer as if you are a biomedical expert.\n",
        "\n",
        "Question:\n",
        "{question_body}\n",
        "\n",
        "Articles Context:\n",
        "{articles_context}\n",
        "\n",
        "Type of question: yes/no\n",
        "\n",
        "Instructions:\n",
        "1. Provide an ideal answer summarizing the most relevant information from the context provided (maximum 150 words).\n",
        "2. Provide an exact answer that must be either \"yes\" or \"no\".\n",
        "3. Return your answer in JSON format exactly matching the structure below:\n",
        "{{\n",
        "    \"ideal_answer\": <string>,\n",
        "    \"exact_answer\": <string>\n",
        "}}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "8ih_zJIDOVb0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factoid_prompt = PromptTemplate(\n",
        "    input_variables=[\"question_body\", \"articles_context\"],\n",
        "    template=\"\"\"\n",
        "You are a biomedical expert. Answer the following factoid question based on the provided articles context. The articles are ordered by decreasing relevance.\n",
        "Don't mention about given articles in ideal answer, just use the knowledge given in articles and answer as if you are a biomedical expert.\n",
        "\n",
        "Question:\n",
        "{question_body}\n",
        "\n",
        "Articles Context:\n",
        "{articles_context}\n",
        "\n",
        "Type of question: factoid\n",
        "\n",
        "Instructions:\n",
        "1. Provide an ideal answer summarizing the most relevant information from the context provided (maximum 150 words).\n",
        "2. Provide an exact answer as a list of lists containing up to 5 entity names (up to 5 inner lists are allowed), (e.g., up to 5 names of drugs),numbers, or similar short expressions, ordered by decreasing confidence.\n",
        "   Each entity can be considered as a factoid answer to the question.\n",
        "   It is not neccessary to return upto 5 inner list , it is the max limit, if you think only less than 5 answers exist for the question , return those only in decreasing order of confidence.\n",
        "   Note: Each inner list must contain exactly one element/entity/string (1 element but not neccesarily 1 word, an entity can be a combination of words).\n",
        "3. Return your answer in JSON format exactly matching the structure below:\n",
        "{{\n",
        "    \"ideal_answer\": <string>,\n",
        "    \"exact_answer\": <list of lists of strings>\n",
        "}}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "rGMxoOLiOp2m"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_prompt = PromptTemplate(\n",
        "    input_variables=[\"question_body\", \"articles_context\"],\n",
        "    template=\"\"\"\n",
        "You are a biomedical expert. Answer the following list question based on the provided articles context. The articles are ordered by decreasing relevance.\n",
        "Don't mention about given articles in ideal answer, just use the knowledge given in articles and answer as if you are a biomedical expert.\n",
        "\n",
        "Question:\n",
        "{question_body}\n",
        "\n",
        "Articles Context:\n",
        "{articles_context}\n",
        "\n",
        "Type of question: list\n",
        "\n",
        "Instructions:\n",
        "1. Provide an ideal answer summarizing the most relevant information from the context provided (maximum 150 words).\n",
        "2. Provide an exact answer as a list of lists corresponding to the entities sought by the question.\n",
        "Each inner list entity will be jointly taken to constitute a single answer for the list type question asked.\n",
        "Each inner list will contain one of the entities (or numbers, or other similar short expressions) seeked by the question.\n",
        "Note: Each inner list must contain exactly one element/entity/string (1 element but not neccesarily 1 word, an entity can be a combination of words).\n",
        "3. Return your answer in JSON format exactly matching the structure below:\n",
        "{{\n",
        "    \"ideal_answer\": <string>,\n",
        "    \"exact_answer\": <list of lists of strings>\n",
        "}}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "aknpyNfQPgx2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"question_body\", \"articles_context\"],\n",
        "    template=\"\"\"\n",
        "You are a biomedical expert. Answer the following summary question based on the provided articles context. The articles are ordered by decreasing relevance.\n",
        "Don't mention about given articles in ideal answer, just use the knowledge given in articles and answer as if you are a biomedical expert.\n",
        "\n",
        "Question:\n",
        "{question_body}\n",
        "\n",
        "Articles Context:\n",
        "{articles_context}\n",
        "\n",
        "Instructions:\n",
        "1. Provide an ideal answer summarizing the most relevant information from the context provided (maximum 150 words).\n",
        "2. Return your answer in JSON format exactly matching the structure below:\n",
        "{{\n",
        "    \"ideal_answer\": <string>\n",
        "}}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "dy5cX1JWRR7H"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippet_prompt = PromptTemplate(\n",
        "    input_variables=[\"question_body\", \"articles_context\"],\n",
        "    template=\"\"\"\n",
        "You are a biomedical expert. Given the following question and the content of several articles (each article has its document ID, title, and abstract), extract relevant text snippets that answer the question.\n",
        "The snippets should not be modified in any form and should just be a part of original text provided and should contain somewhat relevant information that can answer or answer atleast a part of the question.\n",
        "This can be seen as extractive summarization.\n",
        "Return at most 10 snippets in descending order of relevance in usefulness to answer the question.\n",
        "\n",
        "Question:\n",
        "{question_body}\n",
        "\n",
        "Articles Context:\n",
        "{articles_context}\n",
        "\n",
        "For each snippet, include:\n",
        "- \"document\": the article's unique identifier (PMID)\n",
        "- \"section\": indicate whether the snippet is extracted from the \"title\" or \"abstract\"\n",
        "- \"text\": the exact snippet text.\n",
        "Return your answer in JSON format exactly matching the structure below:\n",
        "{{\n",
        "    \"snippets\": [\n",
        "        {{\n",
        "            \"document\": <string>,\n",
        "            \"section\": <string>,\n",
        "            \"text\": <string>\n",
        "        }},\n",
        "        ... (up to 10 snippets)\n",
        "    ]\n",
        "}}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "dh_MBq3xu9UT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtractedSnippet(BaseModel):\n",
        "    document_id: int = Field(\n",
        "        ...,\n",
        "        description=\"The document (PMID) from which the snippet is extracted. Just the id as an integer.\"\n",
        "    )\n",
        "    section: str = Field(\n",
        "        ...,\n",
        "        description=\"The section from which the snippet is extracted (either 'title' or 'abstract').\"\n",
        "    )\n",
        "    text: str = Field(\n",
        "        ...,\n",
        "        description=\"The extracted snippet text.\"\n",
        "    )\n",
        "class ExtractedSnippetsOutput(BaseModel):\n",
        "    snippets: List[ExtractedSnippet] = Field(\n",
        "        ...,\n",
        "        description=\"A list of extracted snippets ordered by decreasing relevance. Max length of list = 10.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "JIzHQSywuXby"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_snippets(question_body, article_context, documents, llm):\n",
        "    structured_snippets_llm = llm.with_structured_output(ExtractedSnippetsOutput)\n",
        "    snippet_response = structured_snippets_llm.invoke(\n",
        "        snippet_prompt.format(question_body=question_body, articles_context=article_context)\n",
        "    )\n",
        "    extracted_snippets = snippet_response.snippets\n",
        "    final_snippets = []\n",
        "    for snippet in extracted_snippets[:10]:\n",
        "        doc_id = str(snippet.document_id)\n",
        "        section = snippet.section.lower().strip()\n",
        "        snippet_text = \" \".join(snippet.text.lower().strip().rstrip('.').split())\n",
        "        if doc_id in documents and section in documents[doc_id]:\n",
        "            section_text = \" \".join(documents[doc_id][section].lower().strip().split())\n",
        "            offset = section_text.find(snippet_text)\n",
        "\n",
        "            if offset != -1:\n",
        "                offset_in_begin = offset\n",
        "                offset_in_end = offset + len(snippet_text) - 1\n",
        "            else:\n",
        "                offset_in_begin = 0\n",
        "                offset_in_end = len(section_text) - 1\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "        final_snippet = {\n",
        "            \"document\": doc_id,\n",
        "            \"beginSection\": section,\n",
        "            \"endSection\": section,\n",
        "            \"offsetInBeginSection\": offset_in_begin,\n",
        "            \"offsetInEndSection\": offset_in_end,\n",
        "            \"text\": snippet_text\n",
        "        }\n",
        "        final_snippets.append(final_snippet)\n",
        "    return final_snippets"
      ],
      "metadata": {
        "id": "mSycCBkaueGQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.05)\n",
        "structured_factoid_llm = llm.with_structured_output(FactoidAnswer)\n",
        "structured_list_llm = llm.with_structured_output(ListAnswer)\n",
        "structured_summary_llm = llm.with_structured_output(SummaryAnswer)\n",
        "structured_yesno_llm = llm.with_structured_output(YesNoAnswer)"
      ],
      "metadata": {
        "id": "GfkJFRWFSxPS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_article_context(question_body, api_key):\n",
        "    documents,pmids = retrieve_pubmed_documents(question_body, api_key)\n",
        "    context = \"\"\n",
        "    article_num = 1\n",
        "    for pmid, doc_info in documents.items():\n",
        "        context += f\"Article {article_num}:\\n\"\n",
        "        article_num += 1\n",
        "        context += f\"PMID: {pmid}\\n\"\n",
        "        context += f\"Title: {doc_info['title']}\\n\"\n",
        "        context += f\"Abstract: {doc_info['abstract']}\\n\\n\"\n",
        "        context += \" --- END OF ARTICLE ---\\n\\n\"\n",
        "    if not context:\n",
        "        return None,None,None\n",
        "    return context, pmids, documents"
      ],
      "metadata": {
        "id": "aKQDOELRUR4U"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question_text,api_key,question):\n",
        "    article_context,pmids,documents = generate_article_context(question_text, api_key)\n",
        "    answer_json = {}\n",
        "    answer_json[\"body\"] = question[\"body\"]\n",
        "    answer_json[\"type\"] = question[\"type\"]\n",
        "    answer_json[\"id\"] = question[\"id\"]\n",
        "    answer_json[\"answer_ready\"] = question[\"answerReady\"]\n",
        "    answer_json[\"documents\"]=[]\n",
        "    answer_json[\"snippets\"] =[]\n",
        "    answer_json[\"exact_answer\"] = \"\"\n",
        "    answer_json[\"ideal_answer\"] = \"\"\n",
        "\n",
        "    if not article_context:\n",
        "        return answer_json\n",
        "\n",
        "    if question[\"type\"] == \"yesno\":\n",
        "        prompt = yesno_prompt\n",
        "        answer = structured_yesno_llm.invoke(prompt.format(question_body=question[\"body\"], articles_context=article_context))\n",
        "    elif question[\"type\"] == \"factoid\":\n",
        "        prompt = factoid_prompt\n",
        "        answer = structured_factoid_llm.invoke(prompt.format(question_body=question[\"body\"], articles_context=article_context))\n",
        "    elif question[\"type\"] == \"list\":\n",
        "        prompt = list_prompt\n",
        "        answer = structured_list_llm.invoke(prompt.format(question_body=question[\"body\"], articles_context=article_context))\n",
        "    elif question[\"type\"] == \"summary\":\n",
        "        prompt = summary_prompt\n",
        "        answer = structured_summary_llm.invoke(prompt.format(question_body=question[\"body\"], articles_context=article_context))\n",
        "\n",
        "    answer_json[\"documents\"] = pmids[:10]\n",
        "    snippets = generate_snippets(question[\"body\"], article_context, documents, llm)\n",
        "    answer_json[\"snippets\"] = snippets\n",
        "    answer_json[\"ideal_answer\"] = answer.ideal_answer\n",
        "    if question[\"type\"]!=\"summary\":\n",
        "      answer_json[\"exact_answer\"] = answer.exact_answer\n",
        "    return answer_json"
      ],
      "metadata": {
        "id": "fy-lUxUqVDc6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "find which question queries are not retrieving any pubmed articles"
      ],
      "metadata": {
        "id": "5cVHrBCl7SrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for question in data[\"questions\"]:\n",
        "  _,ids,_ = generate_article_context(mapping[question[\"id\"]],api_key)\n",
        "  if not ids:\n",
        "    q = mapping[question[\"id\"]]\n",
        "    print(f\"No relevant articles found from pubmed. Please recheck the query - {q}. For question - {question['body']}\")\n",
        "print ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxQ90rzI8bYZ",
        "outputId": "dcf3ff10-50b5-4aed-f605-c269d5230d92"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = {\"questions\": []}\n",
        "for question in data[\"questions\"]:\n",
        "  ans[\"questions\"].append(generate_answer(mapping[question[\"id\"]],api_key,question))"
      ],
      "metadata": {
        "id": "d79oV6f--vzt"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"answer.json\", \"w\") as json_file:\n",
        "    json.dump(ans, json_file, indent=4)"
      ],
      "metadata": {
        "id": "oWnf8RAK-Yo6"
      },
      "execution_count": 54,
      "outputs": []
    }
  ]
}